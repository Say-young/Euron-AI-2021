## âœ” CS231n 2ì£¼ì°¨ ì˜ˆìŠµê³¼ì œ

(5:00~)

### 1. ğŸ˜º Image Classification pipeline
* ì´ë¯¸ì§€ ë¶„ë¥˜ëŠ” ì»´í“¨í„° ë¹„ì „ì˜ ê°€ì¥ ë©”ì¸ task ì¤‘ í•˜ë‚˜
    * input image -> ë¼ë²¨ë§ ë˜ì–´ ìˆëŠ” ì´ë¯¸ì§€êµ°ë“¤ì„ ì‚¬ìš©í•´ ë“¤ì–´ì˜¨ ì´ë¯¸ì§€ë¥¼ ì¸ì§€(ì¹´í…Œê³ ë¦¬ì— í• ë‹¹)
    * ì´ë¯¸ì§€ê°€ 800x600 í”½ì…€ì´ë©´ ê° í”½ì…€ì€ RGBë¥¼ í‘œí˜„í•˜ê¸° ìœ„í•œ 3ìë¦¬ì˜ ìˆ˜ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŒ (= ë§¤ìš° ë§ì€ ì–‘ì˜ ìˆ˜ë“¤!)
    * ì´ ìˆ˜ë“¤ë¡œ ë¼ë²¨ë§ëœ ë°ì´í„°ì— ë”°ë¼ ì´ ì´ë¯¸ì§€ê°€ ì–´ë–¤ êµ°ì— ì†í•˜ëŠ”ì§€ ë¶„ë¥˜í•˜ëŠ” ê²ƒì€ ì‚¬ì‹¤ ë§¤ìš° ì–´ë ¤ìš´ ì¼ì´ë‹¤. (ë¬¼ì²´ê°€ ë°”ë€ŒëŠ” ê²ƒì€ ë¬¼ë¡ , ëŒ€ìƒì´ ê°™ì•„ë„ ì¹´ë©”ë¼ê°€ ì›€ì§ì´ê±°ë‚˜ ë¹›ì˜ ìœ„ì¹˜ê°€ ë‹¬ë¼ì§€ë©´ í”½ì…€ê°’ì´ ë‹¬ë¼ì§„ë‹¤.)

* sementic gap
    * ì»´í“¨í„°ëŠ” ì´ë¯¸ì§€ë¥¼ ìˆ«ìë¡œ ì¸ì‹í•œë‹¤

* How?
    1. Attempts have been made
        * find edges(compute the edges of image) -> try to categorize all the different corners and boundaries...
        * ë‹¤ë£¨ê¸° í˜ë“¤ê³ , ì´ ë°©ëŒ€í•œ ì‘ì—…ì„ ì¹´í…Œê³ ë¦¬ë§ˆë‹¤ ì „ë¶€ ì‹¤í–‰í•´ì•¼ í•¨.
    2. Data-Driven Approach
        1. ì¸í„°ë„·ì—ì„œ ë§¤ìš° ë§ì€ ì–‘ì˜ ë°ì´í„°ì…‹(ì´ë¯¸ì§€)ë¥¼ ëª¨ì€ë‹¤
        2. ë°ì´í„°ë“¤ì„ í•™ìŠµì„ í†µí•´ êµ¬ë¶„í•˜ê³  ì •ë¦¬í•´ì„œ ëª¨ë¸(ì´ëŸ¬í•œ ì´ë¯¸ì§€ ì¹´í…Œê³ ë¦¬ë“¤ì„ ì–´ë–»ê²Œ ì¸ì‹/ë¶„ë¥˜í•˜ëŠ”ì§€ì— ëŒ€í•´ í•™ìŠµí•œ ì§€ì‹ì„ ìš”ì•½í•œ ê²ƒ)ì„ ë§Œë“ ë‹¤
        3. ì´ ëª¨ë¸ì„ ì‚¬ìš©í•´ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ì¸ì‹

* train
    * input images and labels output a model
* predict
    * input the model and make predictions for images

***

#### ì„¸ë¯¸ë‚˜ í•„ê¸° ì¶”ê°€

* ê·œì¹™ ê¸°ë°˜ íŒë‹¨ì˜ ë¬¸ì œì 
    * view point(ì‚¬ì§„ ì°ì€ ê°ë„)
    * illumination (ë°ê¸°)
    * deformation
    * occulusion
    * background clutter (ë¬¼ì²´ê°€ ë°°ê²½ê³¼ ë§¤ìš° í¡ì‚¬í•œ ê²½ìš°)
    * interclass variation (ì—¬ëŸ¬ ì¢…ì´ í•œ ì´ë¯¸ì§€ì—)

* í•˜ì§€ë§Œ ê°ì²´ í•˜ë‚˜í•˜ë‚˜ë¥¼ ëª¨ë‘ êµ¬ë¶„í•´ë‚´ëŠ” ê·œì¹™ì„ ëª¨ë‘ ì‚¬ëŒì´ ì •ì˜í•˜ëŠ” ê²ƒì€ ì–´ë µë‹¤.
    * ê·¸ë˜ì„œ ë‚˜ì˜¨ data driven approach
        * ì•ˆì •ì„± : image inputì´ ë‹¤ì–‘í•˜ê²Œ ì£¼ì–´ì§€ê¸° ë•Œë¬¸ì— ì¼ì • ë¶€ë¶„ ë¶ˆì•ˆì •ì„± í•´ì†Œ ê°€ëŠ¥
        * í™•ì¥ì„±
    * data set(labellig ëœ ì´ë¯¸ì§€ ìˆ˜ì§‘) -> train(classifierì„ í•™ìŠµì‹œí‚´) -> evaluate(ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ inputìœ¼ë¡œ ì£¼ê³  ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ íŒë‹¨)

***


### 2. ğŸ–¥ first classifier: Nearest Neighbor
* í•™ìŠµëœ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ê¸°ì–µí•˜ê³ 
* ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ í•™ìŠµëœ ë°ì´í„°ë“¤ ì¤‘ ê°€ì¥ ë¹„ìŠ·í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ëŠ”ë‹¤.

---

* Manhattan distance to compare images
    * ê°ê°ì˜ í”½ì…€ì„ ë¹„êµ(tst image - training image)í•´ì„œ ëª¨ë“  ì¹¸ì˜ ê°’ì„ ë”í•˜ëŠ” ë°©ë²•
    * CIFAR10 : ë¨¸ì‹ ëŸ¬ë‹ì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ì…‹

    ---

    * memorize training data
        ![image](https://user-images.githubusercontent.com/55133871/112739477-9a8e5500-8faf-11eb-9988-327cdbe7bc5c.png)

    * L1 í•¨ìˆ˜ë¥¼ ì´ìš©í•´ training set ì¤‘ ê°€ì¥ ë¹„ìŠ·í•œ ê²ƒì„ ì°¾ëŠ” ê³¼ì •
        ![image](https://user-images.githubusercontent.com/55133871/112739492-abd76180-8faf-11eb-986c-a87722eaa1d2.png)

    * Q) ì´ ì˜ˆì‹œë¥¼ ì‚¬ìš©í•˜ë©´ í•™ìŠµê³¼ ì˜ˆì¸¡ì— ê±¸ë¦¬ëŠ” ì‹œê°„ì€?
    * A) í•™ìŠµì—ëŠ” O(1), ì˜ˆì¸¡ì—ëŠ” O(N)
        * ëª¨ë“  ë°ì´í„°ë¥¼ ë¹„êµí•´ ì˜ˆì¸¡í•˜ëŠ” ê³¼ì •ì— ê±¸ë¦¬ëŠ” ì‹œê°„ì´ ê¸¸ë‹¤. í•™ìŠµì— ê±¸ë¦¬ëŠ” ì‹œê°„ì€ ê¸¸ì–´ë„ ë˜ì§€ë§Œ ì˜ˆì¸¡ì€ ë¹¨ë¦¬ ë˜ì–´ì•¼ í•œë‹¤. ë‹¤ì–‘í•œ ë””ë°”ì´ìŠ¤ë¡œ ì ‘ê·¼í•˜ëŠ” ì‚¬ìš©ìë“¤ì€ ë¹ ë¥´ê²Œ ì´ë¯¸ì§€ê°€ ë¶„ë¥˜ë˜ê¸¸ ì›í• í…Œë‹ˆê¹Œ.

    ---

    * decision reasons
        ![image](https://user-images.githubusercontent.com/55133871/112739620-c4944700-8fb0-11eb-922e-d4524f6a4c21.png)
        * (K=1) ì´ˆë¡ìƒ‰ areaì— ë…¸ë€ìƒ‰ ì ì´ ìˆê³ , íŒŒë€ìƒ‰ ì˜ì—­ìœ¼ë¡œ ì‚ì ¸ë‚˜ê°„ ì´ˆë¡ìƒ‰ areaê°€ ìˆê³  ë“±ë“±ì˜ ì ìœ¼ë¡œ ì¸í•´ ì´ê²ƒì€ noiseê°€ ë‚€ ì¢‹ì§€ ì•Šì€ ìƒíƒœë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.
        * K-Nearest Neighbors
            * k ê°’ì„ ì¡°ì •í•´ smoothí•œ ê²°ê³¼ê°’ì„ ë‚¸ë‹¤
            * white region : there was no majority among the k-nearest neighbors

---

* K-Nearest Neighbors(kNN / lazy model) : Distance Metric
    * ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ê¸°ì¡´ ë°ì´í„° ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ kê°œ ì´ì›ƒì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²• (ëª¨ë¸ì„ ë³„ë„ë¡œ êµ¬ì¶•í•˜ì§€ ì•Šê³  ê´€ì¸¡ì¹˜ë§Œì„ ì´ìš©)
    * k=1ì€ ë‹¨ 1ê°œì˜ ì´ì›ƒë§Œ ë³´ê³  ì˜ˆì¸¡í•˜ëŠ” ê²ƒ // kê°€ ë„ˆë¬´ ì‘ì„ ê²½ìš° overfitting, ë„ˆë¬´ í´ ê²½ìš° underfitting
    * ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‘ì—… ì´ì™¸ì—ë„ ë¬¸ì¥ ìœ ì‚¬ë„ ë“± ë‹¤ì–‘í•œ ê²ƒì„ ë¶„ë¥˜í•˜ëŠ”ë° ì´ ì•Œê³ ë¦¬ì¦˜ì„ í™•ì¥í•´ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

    ![image](https://user-images.githubusercontent.com/55133871/112739818-72542580-8fb2-11eb-93df-6ee20bbb1676.png)
    * L1(Manhattan) distance
        * ë‘ ì ì˜ ì°¨ì˜ ì ˆëŒ“ê°’(ê±°ë¦¬) ë‚˜íƒ€ëƒ„. ì¢Œí‘œê³„ì— ë”°ë¼ ë‹¬ë¼ì§
    * L2(Euclidean) distance
        * ë‘ ì  ì‚¬ì´ì˜ 'ì§ì„  ê±°ë¦¬' ë‚˜íƒ€ëƒ„. ì¢Œí‘œê³„ì˜ ì˜í–¥ì„ ë°›ì§€ ì•ŠìŒ

    * Why distance?
        * ê±°ë¦¬ëŠ” ì¼ì¢…ì˜ ìœ ì‚¬ë„(similarity)ì™€ ê°™ì€ ê°œë…
        * ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ ìˆ˜ë¡ íŠ¹ì„±(feature)ë“¤ì´ ë¹„ìŠ·í•˜ë‹¤ëŠ” ëœ»

    ---

    * robust
        * ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ì¼ë°˜í™”(generalization)ëŠ” ì¼ë¶€ íŠ¹ì • ë°ì´í„°ë§Œ ì˜ ì„¤ëª…í•˜ëŠ”(=overfitting) ê²ƒì´ ì•„ë‹ˆë¼ ë²”ìš©ì ì¸ ë°ì´í„°ë„ ì í•©í•œ ëª¨ë¸ì„ ì˜ë¯¸í•œë‹¤. ì¦‰, ì˜ ì¼ë°˜í™”í•˜ê¸° ìœ„í•´ì„œëŠ” ì´ìƒì¹˜ë‚˜ ë…¸ì´ì¦ˆê°€ ë“¤ì–´ì™€ë„ í¬ê²Œ í”ë“¤ë¦¬ì§€ ì•Šì•„ì•¼(=robust) í•œë‹¤.

    ---

    * parameters
        * ëª¨ë¸ ë‚´ë¶€ì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•œ ë³€ìˆ˜ë¡œ ë°ì´í„°ë¥¼ í†µí•´ ì‚°ì¶œ ê°€ëŠ¥í•œ ê°’. í•™ìŠµí•  ë•Œ ëª¨ë¸ì— ì˜í•´ ìš”êµ¬ë˜ëŠ” ê°’ë“¤
        * ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ ê²°ì •í•˜ë©° ì£¼ë¡œ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµë˜ê³  ì‚¬ìš©ìê°€ ì •í•˜ì§€ ì•ŠìŒ
        * ì•Œê³ ë¦¬ì¦˜ì˜ ìµœì í™” ê³¼ì •ì—ì„œ ì •í•´ì§

    * Parametric Model
        * ë°ì´í„°ê°€ íŠ¹ì • ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ ê°€ì •
        * ê²°ì •í•´ì•¼í•˜ëŠ” íŒŒë¼ë¯¸í„°ì˜ ì¢…ë¥˜ì™€ ìˆ˜ê°€ ê²°ì •ë˜ì–´ ìˆìŒ
        * ìš°ì„  ëª¨ë¸ì˜ í˜•íƒœë¥¼ ê²°ì •í•˜ê³  ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµì„ í†µí•´ ë°œì „ì‹œí‚¤ëŠ” ë°©ì‹
        * Training dataì— ëŒ€í•´ ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ì •ë³´ë¥¼ ìš”ì•½í•˜ì—¬ Wì— ì €ì¥
        * Test í•  ë•Œ ì‹¤ì œ training dataë¥¼ ì‚¬ìš©í•  í•„ìš” ì—†ìŒ ( kNN )

    * Non â€“ Parametric Model
        * ë°ì´í„°ê°€ íŠ¹ì • ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ëŠ” ê°€ì • ì—†ìŒ (ë” flexible)
        * í•™ìŠµì— ë”°ë¼ íŠœë‹í•  íŒŒë¼ë¯¸í„°ê°€ ëª…í™•í•˜ê²Œ ì •í•´ì ¸ ìˆì§€ ì•ŠìŒ
        * Dataì— ëŒ€í•œ ì‚¬ì „ì§€ì‹ì´ ì „í˜€ ì—†ì„ ë•Œ ìœ ìš©
        * ë” í° ë°ì´í„°ë¥¼ í•„ìš”ë¡œ í•˜ê³  í•™ìŠµì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼

    * â— hyperparameters
        * ëª¨ë¸ì—ì„œ ì™¸ì ì¸ ìš”ì†Œë¡œ, ë°ì´í„° ë¶„ì„ì„ í†µí•´ ì–»ì–´ì§€ëŠ” ê°’ì´ ì•„ë‹ˆë¼ ì‚¬ìš©ìê°€ ì§ì ‘ ì •í•˜ëŠ” ê°’
        * ëª¨ë¸ì˜ parameter ê°’ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ê³¼ì •ì—ì„œ ì‚¬ìš©
        * ê²½í—˜ì— ì˜í•´ ì •í•´ì§€ëŠ” ê²½ìš°ê°€ ë§ì•„ ì—¬ëŸ¬ ë²ˆ ìˆ˜í–‰í•´ë³´ë©° ìµœì ì˜ ê°’ì„ ì°¾ìŒ

        ---

        * what is the best value of k to use?
        * what is the best distance to use?
        * choice about the algorithm that we set rather than learn
            * problem-dependent
            * must try them all out and see what works best.

        1. validation data
            ![image](https://user-images.githubusercontent.com/55133871/112740071-ba744780-8fb4-11eb-8d8d-8006a58cef6e.png)
            * validation ë°ì´í„°ì™€ test ë°ì´í„° ì‚¬ì´ì˜ ì—„ê²©í•œ êµ¬ë¶„ì„ ë‘ëŠ” ê²ƒì€ ë§¤ìš° ì¤‘ìš”
            * Training set: ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” data
            * Validation set: ìµœì í™”ë¥¼ ìœ„í•´ Hyperparameter Tuningì— ì‚¬ìš©
            * Test set: ëª¨ë¸ì˜ ìµœì¢… ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´ ì‚¬ìš©
        
        2. cross-validation
            * ëª¨ë“  ë°ì´í„°ë¥¼ í™œìš©í•¨. íŠ¸ê²… ë°ì´í„°ì— overfitting ë˜ëŠ” ê²ƒì„ ë°©ì§€. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê¸° ë•Œë¬¸ì— ë°ì´í„°ê°€ ì¶©ë¶„íˆ í´ ë•ŒëŠ” ì‚¬ìš©X
            ![image](https://user-images.githubusercontent.com/55133871/112740208-083d7f80-8fb6-11eb-8f77-c9320e2ff8ac.png)
            * ê°•ì˜ ìë£Œì— ìˆëŠ” í‘œì˜ ê²½ìš°, seens that k ~=7 works best for this data
            * K-fold Validation
                * Kê°œì˜ foldë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•œ í›„ ê°ê° í•œ foldì˜ ë°ì´í„°ë¥¼ validation setìœ¼ë¡œ í™œìš©í•´ ì´ Kë²ˆ ê²€ì¦í•˜ê³  í‰ê· ì„ ëƒ„
                * ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì „ì²´ì ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŒ

    ---

    * k-Nearest Neighbor on images never used.
        * very slow at test time : test ì‹œê°„ì´ ì˜¤ë˜ ì†Œìš”ëœë‹¤ëŠ” ê²ƒì€ í° ê²°ì 
        * distance metrics on pixels are not informative
            * ì‚¬ëŒì˜ ëˆˆìœ¼ë¡œëŠ” ë‹¤ë¥¸ ì´ë¯¸ì§€ë¼ëŠ” ê²ƒì„ ì¸ì‹í•˜ëŠ”ë° ì»´í“¨í„°ëŠ” ì˜ ì¸ì‹í•˜ì§€ ëª»í•¨..
            * ê·¸ë˜ì„œ ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ë°ì´í„° ì…‹ì´ ë§ì„ ìˆ˜ë¡ ì¢‹ì§€ë§Œ ë¬¼ë¡  ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ì˜ ìˆ˜ëŠ” ì œí•œì ì´ê¸° ë•Œë¬¸ì—, í•™ìŠµì…‹ì— ê°€ì§œ ë°ì´í„°(fake data)ë¥¼ í¬í•¨í•  ìˆ˜ ìˆë‹¤.
            * Augmentation
                * Training setê³¼ í˜„ì‹¤ì˜ test set ì‚¬ì´ì˜ ê´´ë¦¬ê° ì¡´ì¬
                * ì„ì˜ì˜ ì¡ìŒì´ë‚˜ translationì„ training setì— ê°€í•´ì„œ ê´´ë¦¬ê°ì„ ì¤„ì´ê³  ì„±ëŠ¥ í–¥ìƒ
                * ë°ì´í„° í¬ê¸°ê°€ ì‘ì€ ê²½ìš° ë°ì´í„°ì…‹ì„ ëŠ˜ë¦¬ê¸° ìœ„í•´ ì‚¬ìš©
                * flip, noise, contrast, combination
        * curse of dimensionality
            ![image](https://user-images.githubusercontent.com/55133871/112740585-0aeda400-8fb9-11eb-8281-c8544598c047.png)
            * kNNì´ ì˜ ì‘ë™í•˜ë ¤ë©´ data setì´ ê³µê°„ ì „ì²´ë¥¼ ë®ì–´ì•¼ í•¨. dimensionì´ ë†’ì•„ì§ˆìˆ˜ë¡ ë°ì´í„° ë§ì´ í•„ìš” = ë¹„í‘œìœ¨ì 
            * the number of training examples that we need to densely cover the space grows exponentially with the dimension.

    ---

    * summary
        ![image](https://user-images.githubusercontent.com/55133871/112740420-df1dee80-8fb7-11eb-9c2e-c22f0c7ed18d.png)


### 3. ğŸ–¥ linear classifier : SUPER IMPORTANT
> ë”¥ëŸ¬ë‹ì€.. ë ˆê³ ì™€ë„ ê°™ë‹¤. ì°¨ê³¡ì°¨ê³¡.. ì—¬ëŸ¬ê°œì˜ linear classifier...

![image](https://user-images.githubusercontent.com/55133871/112740874-599c3d80-8fbb-11eb-88c8-0ca1e35f3924.png)
* W
    * Training dataì— ëŒ€í•œ ì •ë³´ê°€ ìš”ì•½ëœ ë²¡í„°
    * k-nearestì—ì„œëŠ” parameterê°€ ì—†ê³  ì „ì²´ í•™ìŠµëœ ë°ì´í„°ë¥¼ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í–ˆì—ˆë‹¤.
    * í•˜ì§€ë§Œ~ we're going to summarize our knowledge of the training data and stick all that knowledge into these parameters, W.
    * ê·¸ë ‡ê²Œ ë˜ë©´ ì‹¤ì œ training dataë“¤ì€ í•„ìš” ì—†ê³  í…ŒìŠ¤íŠ¸í•  ë•Œ Wë§Œ ì‚¬ìš©í•˜ë©´ ëœë‹¤ëŠ” ë§ì”€!
* F
    * ì¡°ê±´ì— ë§ê²Œ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
* b
    * training dataì™€ ìƒí˜¸ì‘ìš©í•˜ì§€ ì•ŠëŠ” ìƒìˆ˜
    * ì˜ˆë¥¼ ë“¤ì–´ ê³ ì–‘ì´ë³´ë‹¤ ê°•ì•„ì§€ ì‚¬ì§„ì´ í›¨ì”¬ ë” ë§ì„ ê²½ìš° ê³ ì–‘ì´ì˜ í¸í–¥(bias) ìš”ì†Œê°€ ë‹¤ë¥¸ ê²ƒë³´ë‹¤ ë” ë†’ë‹¤.

* ì´ëŸ¬í•œ ëª¨ìŠµì„
    ![image](https://user-images.githubusercontent.com/55133871/112740996-97e62c80-8fbc-11eb-8242-c3b79eaa24d9.png)
    * ì´ë¯¸ì§€ëŠ” 3ì°¨ì›ì˜ shape(RGBë‹ˆê¹Œ)
    * ê¸°ì¡´ì˜ ì €ì¥ë˜ì–´ ìˆë˜ Wì™€ ê³±í•´ì„œ > ì´ë¯¸ì§€ì˜ pixel valuesë“¤ì„ í•˜ë‚˜ì˜ ê¸´ column vectorë¡œ ë§Œë“¤ì–´ 1ì°¨ì›ì˜ ê°’ìœ¼ë¡œ ë§Œë“¦
    * ê·¸ í›„ í•„ìš”ì— ë”°ë¼ ì„ì˜ë¡œ Bë¥¼ ë”í•´ì£¼ë©´
    * ìµœì¢…ì ì¸ scoreê°€ ë‚˜ì˜¨ë‹¤! (ê° classì— ëŒ€í•œ scoreì´ ë‹´ê¸´ ë²¡í„°)

    * to go back to this idea of images as points and high dimensional space.
        ![image](https://user-images.githubusercontent.com/55133871/112741052-1347de00-8fbd-11eb-8f71-4d22544de4be.png)

    * ë³´ì¶© í•„ìš”
        ![image](https://user-images.githubusercontent.com/55133871/112741074-31add980-8fbd-11eb-92aa-1278a05a63ba.png)
        ![image](https://user-images.githubusercontent.com/55133871/112741112-746fb180-8fbd-11eb-9e07-0d0543691a37.png)